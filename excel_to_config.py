"""
=================================================================
  EXCEL-TO-CONFIG CONVERTER (Grandma Profile)

  Reads the grandma Excel sheet and produces a story_config.json
  that the existing run_story.py pipeline can consume, with
  per-scene character and environment reference switching.

  HOW TO USE:
  1. Run: python excel_to_config.py
  2. It creates a fresh story_config.json
  3. Then run: python run_story.py

  OR one command:
     python excel_to_config.py --run

  OPTIONS:
     python excel_to_config.py --title "Tea Time with Grandma"
     python excel_to_config.py --episode 3
     python excel_to_config.py --narration-file narration.txt
=================================================================
"""

import json
import re
import sys
from pathlib import Path
from datetime import datetime

try:
    import openpyxl
except ImportError:
    print("ERROR: openpyxl not installed. Run: pip install openpyxl")
    sys.exit(1)


EXCEL_PATH = Path(__file__).parent / "data" / "story_prompts_grouped_with_blank_lines_and_suffix.xlsx"

# Character reference image paths (must exist or will be generated by run_story.py)
CHARACTER_DEFAULTS = {
    "C1": {
        "name": "Narrator",
        "image_path": "data/characters/narrator_01.png",
    },
    "C2": {
        "name": "Grandmother",
        "image_path": "data/characters/grandmother_01.png",
    },
    "C3": {
        "name": "Miso",
        "image_path": "data/characters/miso_01.png",
    },
}

# Environment names for human-readable output
ENVIRONMENT_NAMES = {
    "E1": "plain_bg",
    "E2": "kitchen",
    "E3": "living_room",
    "E4": "window_view",
    "E5": "garden",
    "E6": "fields",
    "E7": "hallway",
    "E8": "bathroom",
}


def _normalize_char_code(raw) -> str:
    """Normalize character_code from Excel to string like '0', '1', '1|2', etc."""
    if raw is None:
        return "0"
    s = str(raw).strip()
    # Integer values come through as '0', '1', '2', '3'
    # Pipe-separated come through as '1|2', '1|2|3', '1|3'
    return s


def _normalize_env_code(raw) -> str:
    """Normalize environment_code from Excel to string like 'E2', 'E3', etc."""
    if raw is None:
        return "E1"
    s = str(raw).strip()
    if s.startswith("E"):
        return s
    # Numeric: prefix with E
    try:
        return f"E{int(float(s))}"
    except (ValueError, TypeError):
        return "E1"


def _char_code_to_list(code_str: str) -> list[str]:
    """Convert character code string to list of 'C1', 'C2', etc.

    '0' -> []
    '1' -> ['C1']
    '1|2' -> ['C1', 'C2']
    '1|2|3' -> ['C1', 'C2', 'C3']
    """
    if code_str == "0":
        return []
    parts = code_str.split("|")
    return [f"C{p.strip()}" for p in parts if p.strip()]


def read_excel(excel_path: Path) -> list[dict]:
    """Read all data rows from the Excel workbook, across all sheets.

    Returns list of dicts sorted by image number:
        [{"image": int, "prompt": str, "character_code": str, "environment_code": str, "sheet": str}, ...]
    """
    wb = openpyxl.load_workbook(excel_path, read_only=True, data_only=True)
    rows = []

    for sheet_name in wb.sheetnames:
        if sheet_name.upper() == "INDEX":
            continue

        ws = wb[sheet_name]
        header = None
        for row in ws.iter_rows(values_only=True):
            if header is None:
                header = [str(c).strip().lower() if c else "" for c in row]
                continue

            if row[0] is None:
                continue

            try:
                image_num = int(float(row[0]))
            except (ValueError, TypeError):
                continue

            prompt = str(row[1]).strip() if row[1] else ""
            char_code = _normalize_char_code(row[2])
            env_code = _normalize_env_code(row[3])

            rows.append({
                "image": image_num,
                "prompt": prompt,
                "character_code": char_code,
                "environment_code": env_code,
                "sheet": sheet_name,
            })

    wb.close()

    # Sort by image number
    rows.sort(key=lambda r: r["image"])
    return rows


def _extract_environment_descriptions(all_rows: list[dict]) -> dict[str, str]:
    """Extract environment descriptions from C0 (no-character) scene prompts.

    Returns dict mapping env_code -> description string.
    """
    env_descs = {}
    for row in all_rows:
        if row["character_code"] != "0":
            continue
        env_code = row["environment_code"]
        if env_code == "E1":
            continue
        if env_code not in env_descs:
            # Use first C0 prompt for this environment as its description
            env_descs[env_code] = row["prompt"]
    return env_descs


def _derive_title(all_rows: list[dict]) -> str:
    """Generate a title from scene content keywords."""
    # Look at the first few scene prompts for environment cues
    scene_rows = [r for r in all_rows if r["image"] > 3]
    env_codes_used = set()
    for r in scene_rows[:10]:
        env_codes_used.add(r["environment_code"])

    env_names = [ENVIRONMENT_NAMES.get(e, e) for e in sorted(env_codes_used)]

    if "kitchen" in env_names:
        return "A Quiet Day with Grandmother"
    elif "garden" in env_names:
        return "In Grandmother's Garden"
    else:
        return "An Afternoon with Grandmother"


def _load_grandma_counter() -> int:
    """Load the grandma-specific episode counter."""
    counter_path = Path(__file__).parent / "data" / "episode_counter_grandma.json"
    if counter_path.exists():
        try:
            with open(counter_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            last_ep = data.get("last_episode")
            if isinstance(last_ep, int) and last_ep >= 0:
                return last_ep
        except Exception:
            pass
    return 0


def _save_grandma_counter(episode_num: int):
    """Save the grandma-specific episode counter."""
    counter_path = Path(__file__).parent / "data" / "episode_counter_grandma.json"
    counter_path.parent.mkdir(parents=True, exist_ok=True)
    with open(counter_path, "w", encoding="utf-8") as f:
        json.dump(
            {
                "last_episode": episode_num,
                "updated_at": datetime.now().isoformat(timespec="seconds"),
            },
            f,
            indent=2,
        )


def build_config(
    excel_path: Path = EXCEL_PATH,
    title: str | None = None,
    episode: int | None = None,
    narration_file: str | None = None,
    output_dir: str | None = None,
) -> dict:
    """Build a story_config.json dict from the grandma Excel sheet.

    Args:
        excel_path: Path to the Excel workbook.
        title: Override title. Auto-derived if None.
        episode: Override episode number. Auto-incremented if None.
        narration_file: Path to a text file with narration. Empty string if None.
        output_dir: Output directory for episode assets.

    Returns:
        Config dict ready to write to story_config.json.
    """
    all_rows = read_excel(excel_path)

    if len(all_rows) < 4:
        print(f"ERROR: Expected at least 4 rows, got {len(all_rows)}")
        sys.exit(1)

    # Separate character refs (images 1-3) from scene prompts (images 4+)
    char_rows = [r for r in all_rows if r["image"] <= 3]
    scene_rows = [r for r in all_rows if r["image"] > 3]

    # Episode numbering
    if episode is None:
        episode = _load_grandma_counter() + 1

    # Title
    if title is None:
        title = _derive_title(all_rows)
    title_with_episode = f"{title} - Episode {episode}"

    # Build characters array from rows 1-3
    characters = []
    for row in sorted(char_rows, key=lambda r: r["image"]):
        code = _char_code_to_list(row["character_code"])
        char_code = code[0] if code else f"C{row['image']}"
        defaults = CHARACTER_DEFAULTS.get(char_code, {})
        characters.append({
            "name": defaults.get("name", f"Character_{row['image']}"),
            "description": row["prompt"],
            "code": char_code,
            "image_path": defaults.get("image_path", f"data/characters/char{row['image']}_01.png"),
        })

    # Extract environment descriptions from C0 prompts
    env_descriptions = _extract_environment_descriptions(all_rows)

    # Build environments dict
    environments = {}
    # Collect all unique env codes used in scene rows
    scene_env_codes = sorted(set(r["environment_code"] for r in scene_rows))
    for env_code in scene_env_codes:
        if env_code == "E1":
            continue  # Plain bg, no ref needed
        env_name = ENVIRONMENT_NAMES.get(env_code, env_code.lower())
        env_desc = env_descriptions.get(env_code, "")
        # If no C0 prompt exists (like E7), derive from a scene prompt that uses it
        if not env_desc:
            for r in scene_rows:
                if r["environment_code"] == env_code:
                    env_desc = r["prompt"]
                    break
        environments[env_code] = {
            "name": env_name,
            "description": env_desc,
            "image_path": f"data/environments/grandma_{env_name}.png",
        }

    # Build scenes array and scene_refs (parallel arrays)
    scenes = []
    scene_refs = []
    for row in scene_rows:
        scenes.append(row["prompt"])
        char_codes = _char_code_to_list(row["character_code"])
        scene_refs.append({
            "character_codes": char_codes,
            "environment_code": row["environment_code"],
        })

    # Default scene (first environment used in scenes, for the "scene" field)
    first_env_code = scene_rows[0]["environment_code"] if scene_rows else "E2"
    first_env = environments.get(first_env_code, {})
    default_scene = {
        "name": first_env.get("name", "kitchen"),
        "description": first_env.get("description", ""),
        "image_path": first_env.get("image_path", "data/environments/grandma_kitchen.png"),
    }

    # Narration
    narration = ""
    if narration_file:
        narr_path = Path(narration_file)
        if narr_path.exists():
            narration = narr_path.read_text(encoding="utf-8").strip()
        else:
            print(f"WARNING: Narration file not found: {narr_path}")

    # Determine output dir
    if output_dir is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir_str = f"output/episodes/grandma_ep{episode}_{timestamp}"
    else:
        output_dir_str = output_dir

    config = {
        "title": title_with_episode,
        "description": f"Grandmother's story - Episode {episode}",
        "profile": "grandma_excel",
        "episode": episode,
        "characters": characters,
        "environments": environments,
        "scene": default_scene,
        "scenes": scenes,
        "scene_refs": scene_refs,
        "narration": narration,
        "style": "",
        "settings": {
            "voice": "en-US-AriaNeural",
            "narration_speed": "-15%",
            "music_volume": 0.18,
            "narration_volume": 1.2,
            "resolution": "1920x1080",
            "fps": 24,
            "video_quality": 18,
            "output_versions": ["narrated", "music_only"],
        },
    }

    return config, output_dir_str


# =============================================================================
# CLI
# =============================================================================

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="Convert grandma Excel sheet to story_config.json for the video pipeline"
    )
    parser.add_argument("--excel", default=str(EXCEL_PATH),
                        help="Path to the Excel workbook")
    parser.add_argument("--title", default=None,
                        help="Override video title (auto-derived if not set)")
    parser.add_argument("--episode", type=int, default=None,
                        help="Override episode number (auto-incremented if not set)")
    parser.add_argument("--narration-file", default=None,
                        help="Path to a text file containing narration")
    parser.add_argument("--output", default="story_config.json",
                        help="Output config file path (default: story_config.json)")
    parser.add_argument("--output-dir", default=None,
                        help="Output directory for episode assets")
    parser.add_argument("--run", action="store_true",
                        help="Also run the full pipeline after generating config")
    parser.add_argument("--skip-whisk", action="store_true",
                        help="Skip Whisk image generation (use existing images)")
    parser.add_argument("--upload", action="store_true",
                        help="Upload to YouTube after pipeline completes")
    parser.add_argument("--schedule", type=int, default=None,
                        help="Schedule upload N hours from now (implies --upload)")

    args = parser.parse_args()

    excel_path = Path(args.excel)
    if not excel_path.exists():
        print(f"ERROR: Excel file not found: {excel_path}")
        sys.exit(1)

    config, output_dir = build_config(
        excel_path=excel_path,
        title=args.title,
        episode=args.episode,
        narration_file=args.narration_file,
        output_dir=args.output_dir,
    )

    # Write config
    output_path = Path(args.output)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(config, f, indent=2, ensure_ascii=False)

    # Save counter
    _save_grandma_counter(config["episode"])

    print(f"\n  Grandma Excel Config Generated!")
    print(f"  Title:        {config['title']}")
    print(f"  Episode:      {config['episode']}")
    print(f"  Characters:   {', '.join(c['name'] for c in config['characters'])}")
    env_display = ", ".join(f"{k} ({v['name']})" for k, v in config["environments"].items())
    print(f"  Environments: {env_display}")
    print(f"  Scenes:       {len(config['scenes'])}")
    print(f"  Scene refs:   {len(config['scene_refs'])}")
    print(f"  Narration:    {'Yes' if config['narration'] else 'None (music-only)'}")
    print(f"  Output dir:   {output_dir}")
    print(f"  Saved to:     {output_path}")
    print()

    if args.run:
        print("  Starting pipeline...")
        import subprocess
        upload = args.upload or args.schedule is not None
        cmd = [
            sys.executable,
            "run_story.py",
            "--config", str(output_path),
            "--output-dir", output_dir,
        ]
        if args.skip_whisk:
            cmd.append("--skip-whisk")
        if upload:
            cmd.append("--upload")
        if args.schedule is not None:
            cmd.extend(["--schedule", str(args.schedule)])
        subprocess.run(cmd)
